{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30771aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T19:16:00.851443Z",
     "iopub.status.busy": "2026-01-13T19:16:00.851179Z",
     "iopub.status.idle": "2026-01-13T19:39:47.408934Z",
     "shell.execute_reply": "2026-01-13T19:39:47.408143Z"
    },
    "papermill": {
     "duration": 1426.563332,
     "end_time": "2026-01-13T19:39:47.410483",
     "exception": false,
     "start_time": "2026-01-13T19:16:00.847151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing from /kaggle/input/zno-libs-final/offline_libs...\n",
      "‚úÖ Installation Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 19:16:25.972798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768331786.171742      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768331786.230049      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768331786.706998      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768331786.707045      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768331786.707047      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768331786.707050      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b8d4ebf8dc4c1e89439868d2c1cf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Attaching Adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['alora_invocation_tokens', 'arrow_config', 'ensure_weight_tying', 'peft_version', 'use_bdlora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Candidate IDs: [36155, 60332, 16206, 37114, 24110]\n",
      "‚ö†Ô∏è Path not found, searching...\n",
      "‚úÖ Found at: /kaggle/input/gen-ai-ucu-2025-task-3/zno.test.jsonl\n",
      "üöÄ Starting STABLE RUN (Batch 1) on 751 items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [20:30<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DONE! Saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CLEAN START & INSTALL\n",
    "# ==========================================\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Aggressive cleanup before start\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Install libs offline\n",
    "LIB_PATH = \"offline_libs\"\n",
    "ZIP_PATH = \"/kaggle/input/zno-libs-final/offline_libs.zip\"\n",
    "\n",
    "if not os.path.exists(LIB_PATH):\n",
    "    if os.path.exists(ZIP_PATH):\n",
    "        print(\"üì¶ Unzipping libraries...\")\n",
    "        !unzip -q {ZIP_PATH} -d .\n",
    "    elif os.path.exists(\"/kaggle/input/zno-libs-final/offline_libs\"):\n",
    "        LIB_PATH = \"/kaggle/input/zno-libs-final/offline_libs\"\n",
    "\n",
    "print(f\"üì¶ Installing from {LIB_PATH}...\")\n",
    "!pip install --no-index --find-links={LIB_PATH} bitsandbytes peft accelerate transformers tokenizers safetensors sentencepiece > /dev/null\n",
    "print(\"‚úÖ Installation Complete!\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION (STABILITY MODE)\n",
    "# ==========================================\n",
    "BATCH_SIZE = 1           # <--- –ù–∞–π–±–µ–∑–ø–µ—á–Ω—ñ—à–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç. 0% —Ä–∏–∑–∏–∫—É OOM.\n",
    "MAX_CONTEXT_LEN = 1100   # <--- –ó–º–µ–Ω—à–∏–ª–∏ –∑ 1500. –¶—å–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è —Ç–µ–∫—Å—Ç—É + –ø—Ä–∏–∫–ª–∞–¥—ñ–≤.\n",
    "BASE_MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/7b-instruct/1\" \n",
    "ADAPTER_PATH = \"/kaggle/input/zno-my-adapter\"\n",
    "TEST_FILE_PATH = \"/kaggle/input/zno-data/zno.test.jsonl\" \n",
    "\n",
    "# ==========================================\n",
    "# 3. LOAD MODEL\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError(\"‚ùå RUNNING ON CPU. Turn on GPU!\")\n",
    "\n",
    "print(f\"‚è≥ Loading Model...\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True \n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "print(f\"üîó Attaching Adapter...\")\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH, local_files_only=True)\n",
    "model.eval()\n",
    "\n",
    "# ==========================================\n",
    "# 4. TOKEN MAPPING (Cyrillic Candidates)\n",
    "# ==========================================\n",
    "candidates = [\"–ê\", \"–ë\", \"–í\", \"–ì\", \"–î\"]\n",
    "candidate_ids = []\n",
    "\n",
    "for c in candidates:\n",
    "    ids = tokenizer.encode(c, add_special_tokens=False)\n",
    "    candidate_ids.append(ids[-1])\n",
    "\n",
    "print(f\"üéØ Candidate IDs: {candidate_ids}\")\n",
    "answer_map = {0: \"–ê\", 1: \"–ë\", 2: \"–í\", 3: \"–ì\", 4: \"–î\"}\n",
    "\n",
    "# ==========================================\n",
    "# 5. PROMPT (PAPER OPTIMIZED)\n",
    "# ==========================================\n",
    "EXAMPLES = \"\"\"\n",
    "–ü–∏—Ç–∞–Ω–Ω—è: –°–ª–æ–≤–æ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –ø–æ–º–∏–ª–∫–æ—é —î –≤ —Ä—è–¥–∫—É\n",
    "–í–∞—Ä—ñ–∞–Ω—Ç–∏:\n",
    "–ê: –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–∏–π, –±–∞–ª–∞—Å—Ç–Ω–∏–π, —Ñ–æ—Ä–ø–æ—Å—Ç–Ω–∏–π\n",
    "–ë: –ø–µ—Å—Ç—É–Ω–∏, —Ö–≤–∞—Å—Ç–ª–∏–≤–∏–π, –∫—ñ—Å—Ç–ª—è–≤–∏–π\n",
    "–í: —Å—Ç—É–¥–µ–Ω—Ç—Å—å–∫–∏–π, –¥–∏—Ä–∏–≥–µ–Ω—Ç—Å—å–∫–∏–π, —Ç—É—Ä–∏—Å—Ç—Å—å–∫–∏–π\n",
    "–ì: —Ç–∏–∂–Ω–µ–≤–∏–π, —Å–µ—Ä—Ü–µ–≤–∏–π, –∑–ª—ñ—Å–Ω–∏–π\n",
    "–î: —É—á–∞—Å–Ω–∏–∫, —è—Ö—Ç—Å–º–µ–Ω, —Å—Ç—ñ–ª—å–Ω–∏–∫–æ–≤–∏–π\n",
    "–í—ñ–¥–ø–æ–≤—ñ–¥—å: –ê\n",
    "\n",
    "–ü–∏—Ç–∞–Ω–Ω—è: –£–∫–∞–∂—ñ—Ç—å —Ä—è–¥–æ–∫, —É —è–∫–æ–º—É –≤—Å—ñ —Å–ª–æ–≤–∞ –ø–∏—à—É—Ç—å—Å—è –∑ –≤–µ–ª–∏–∫–æ—ó –ª—ñ—Ç–µ—Ä–∏\n",
    "–í–∞—Ä—ñ–∞–Ω—Ç–∏:\n",
    "–ê: (–®,—à)–µ–≤—á–µ–Ω–∫—ñ–≤—Å—å–∫—ñ –≤—ñ—Ä—à—ñ, (–ö,–∫)–∏—ó–≤—Å—å–∫—ñ –≤—É–ª–∏—Ü—ñ\n",
    "–ë: (–î,–¥)–Ω—ñ–ø—Ä–æ–≤—Å—å–∫—ñ —Ö–≤–∏–ª—ñ, (–õ,–ª)—å–≤—ñ–≤—Å—å–∫–∞ –∫–∞–≤–∞\n",
    "–í: (–ü,–ø)—ñ–≤–¥–µ–Ω–Ω–∏–π (–ë,–±)—É–≥, (–ó,–∑)–æ–ª–æ—Ç—ñ (–í,–≤)–æ—Ä–æ—Ç–∞\n",
    "–ì: (–ù,–Ω)–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π (–ë,–±)–∞–Ω–∫, (–í,–≤)–µ—Ä—Ö–æ–≤–Ω–∞ (–†,—Ä)–∞–¥–∞\n",
    "–î: (–ú,–º)—ñ–Ω—ñ—Å—Ç–µ—Ä—Å—Ç–≤–æ (–û,–æ)—Å–≤—ñ—Ç–∏, (–ö,–∫)–∞–±–º—ñ–Ω\n",
    "–í—ñ–¥–ø–æ–≤—ñ–¥—å: –í\n",
    "\"\"\"\n",
    "\n",
    "def create_prompt(item):\n",
    "    q = item.get('question', '')\n",
    "    if 'answers' in item:\n",
    "        opts = \"\\n\".join([f\"{opt['marker']}: {opt['text']}\" for opt in item['answers']])\n",
    "    else:\n",
    "        opts = str(item.get('answers', ''))\n",
    "    \n",
    "    instruction = \"–î–∞–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å –±—É–∫–≤–æ—é-–≤–∞—Ä—ñ–∞–Ω—Ç–æ–º –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∑ –Ω–∞–¥–∞–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤.\"\n",
    "    return f\"<|im_start|>user\\n{instruction}\\n\\n–ü—Ä–∏–∫–ª–∞–¥–∏:\\n{EXAMPLES}\\n\\n–ü–∏—Ç–∞–Ω–Ω—è: {q}\\n–í–∞—Ä—ñ–∞–Ω—Ç–∏:\\n{opts}<|im_end|>\\n<|im_start|>assistant\\n–í—ñ–¥–ø–æ–≤—ñ–¥—å:\"\n",
    "\n",
    "# ==========================================\n",
    "# 6. INFERENCE LOOP (STABLE LOGITS)\n",
    "# ==========================================\n",
    "if not os.path.exists(TEST_FILE_PATH):\n",
    "    print(\"‚ö†Ô∏è Path not found, searching...\")\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        if \"zno.test.jsonl\" in files:\n",
    "            TEST_FILE_PATH = os.path.join(root, \"zno.test.jsonl\")\n",
    "            print(f\"‚úÖ Found at: {TEST_FILE_PATH}\")\n",
    "\n",
    "test_data = []\n",
    "with open(TEST_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try: test_data.append(json.loads(line))\n",
    "        except: pass\n",
    "\n",
    "print(f\"üöÄ Starting STABLE RUN (Batch 1) on {len(test_data)} items...\")\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_data), BATCH_SIZE)):\n",
    "    # Aggressive Memory Cleanup\n",
    "    if i % 50 == 0: \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    batch_items = test_data[i : i + BATCH_SIZE]\n",
    "    batch_prompts = [create_prompt(item) for item in batch_items]\n",
    "    batch_ids = [item.get('id') for item in batch_items]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch_prompts, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=MAX_CONTEXT_LEN # Reduced length\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode(): \n",
    "        outputs = model(**inputs)\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "        candidate_scores = next_token_logits[:, candidate_ids]\n",
    "        best_indices = torch.argmax(candidate_scores, dim=1).cpu().numpy()\n",
    "\n",
    "    for q_id, idx in zip(batch_ids, best_indices):\n",
    "        results.append({\"id\": q_id, \"answer\": answer_map[idx]})\n",
    "\n",
    "    # Save frequently\n",
    "    if i % 10 == 0:\n",
    "        pd.DataFrame(results).to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# Final Save\n",
    "pd.DataFrame(results).to_csv(\"submission.csv\", index=False)\n",
    "print(f\"‚úÖ DONE! Saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157b689",
   "metadata": {
    "papermill": {
     "duration": 0.026914,
     "end_time": "2026-01-13T19:39:47.465632",
     "exception": false,
     "start_time": "2026-01-13T19:39:47.438718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15042800,
     "isSourceIdPinned": false,
     "sourceId": 126776,
     "sourceType": "competition"
    },
    {
     "datasetId": 9251850,
     "sourceId": 14485074,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9252567,
     "sourceId": 14486258,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 164048,
     "modelInstanceId": 141469,
     "sourceId": 166258,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1432.168358,
   "end_time": "2026-01-13T19:39:50.210114",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-13T19:15:58.041756",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cc1163061fe46aabfc04ab4149ba952": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1b2790a86ce3419588ab68ccf60183dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3432d7c7a03e43b785e6680ef1adce97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48e0e79355474ac48473aaab14e08865": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6bfaae38022e49dfad5d2d9cf9410753": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b2790a86ce3419588ab68ccf60183dd",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_48e0e79355474ac48473aaab14e08865",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá4/4‚Äá[02:26&lt;00:00,‚Äá35.98s/it]"
      }
     },
     "94abe5d568c04534b38c5a7720655400": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96d805f969d940b1b268b4ad43e5c467": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1b8d4ebf8dc4c1e89439868d2c1cf48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f0aebe7c7e024f3898fa11fc507e7135",
        "IPY_MODEL_ca9075ddf7b1484b974f677e23a7fa7d",
        "IPY_MODEL_6bfaae38022e49dfad5d2d9cf9410753"
       ],
       "layout": "IPY_MODEL_96d805f969d940b1b268b4ad43e5c467",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ae7cdc3ac5df4d8c83fbb24aa4ebe5a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca9075ddf7b1484b974f677e23a7fa7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3432d7c7a03e43b785e6680ef1adce97",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ae7cdc3ac5df4d8c83fbb24aa4ebe5a6",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "f0aebe7c7e024f3898fa11fc507e7135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_94abe5d568c04534b38c5a7720655400",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_0cc1163061fe46aabfc04ab4149ba952",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
